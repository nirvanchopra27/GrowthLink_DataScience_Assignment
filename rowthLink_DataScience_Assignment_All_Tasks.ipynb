{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPwnDaboMqWGPGh3ETiz+NX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nirvanchopra27/GrowthLink_DataScience_Assignment/blob/main/rowthLink_DataScience_Assignment_All_Tasks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-RgwcSrfp3k",
        "outputId": "72fc6e65-0c77-43fe-9017-909edf66c8fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-395b6dd1f6f3>:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Age'].fillna(df['Age'].median(), inplace=True)\n",
            "<ipython-input-14-395b6dd1f6f3>:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Titanic Prediction Accuracy: 0.8435754189944135\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.87      0.88       116\n",
            "           1       0.77      0.79      0.78        63\n",
            "\n",
            "    accuracy                           0.84       179\n",
            "   macro avg       0.83      0.83      0.83       179\n",
            "weighted avg       0.84      0.84      0.84       179\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Task 1: Titanic Survival Prediction\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\")\n",
        "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
        "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
        "df.drop(['Cabin', 'Ticket', 'Name', 'PassengerId'], axis=1, inplace=True)\n",
        "\n",
        "df['Sex'] = LabelEncoder().fit_transform(df['Sex'])\n",
        "df['Embarked'] = LabelEncoder().fit_transform(df['Embarked'])\n",
        "\n",
        "X = df.drop('Survived', axis=1)\n",
        "y = df['Survived']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Titanic Prediction Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 3: Iris Flower Classification\n",
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Iris Classification Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxcinQgsgdze",
        "outputId": "b94cb082-8d20-4097-8fe0-b5bf7d55f5d1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iris Classification Accuracy: 0.9666666666666667\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         9\n",
            "           1       0.92      1.00      0.96        11\n",
            "           2       1.00      0.90      0.95        10\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.97      0.97      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 4: Sales Prediction\n",
        "sales_df = pd.read_csv(\"https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv\")\n",
        "sales_df.dropna(inplace=True)\n",
        "\n",
        "sales_df['Type'] = LabelEncoder().fit_transform(sales_df['Type'])\n",
        "X = sales_df[['Horsepower', 'EngineSize', 'Type', 'RPM', 'Weight']]\n",
        "y = sales_df['Price']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "model = GradientBoostingRegressor()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Sales Prediction RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4HedhlYguWF",
        "outputId": "8dc78fad-8ff9-4f5b-a0f5-2b777624e2ff"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sales Prediction RMSE: 5.441091940492561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TASK2 MOVIES RATING PREDICTIONS\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "column_names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
        "# The file 'u.data' is likely not in the current directory.\n",
        "# Provide the correct path to the file, or download it if needed.\n",
        "# Assuming the file is located at '/path/to/u.data'\n",
        "# Replace with the actual path if different\n",
        "try:\n",
        "    # Assign the dataframe to a new variable name to avoid conflicts\n",
        "    ratings_df = pd.read_csv('u.data', sep='\\t', names=column_names)\n",
        "except FileNotFoundError:\n",
        "    print(\"File 'u.data' not found. Downloading...\")\n",
        "    # Alternatively, you can download the file:\n",
        "    !wget http://files.grouplens.org/datasets/movielens/ml-100k/u.data -O u.data\n",
        "    ratings_df = pd.read_csv('u.data', sep='\\t', names=column_names) # Use ratings_df here as well\n",
        "\n",
        "\n",
        "# For simplicity, we'll predict the rating based on user_id and item_id\n",
        "X = ratings_df[['user_id', 'item_id']] # Use ratings_df instead of df\n",
        "y = ratings_df['rating'] # Use ratings_df instead of df\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(f\"Movie Rating Prediction RMSE: {rmse:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Os20dOXWgxJv",
        "outputId": "98a00ebf-5cea-4b54-83c2-a75c08efb5bc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Movie Rating Prediction RMSE: 1.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 5: Credit Card Fraud Detection\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Load dataset\n",
        "try:\n",
        "    fraud_df = pd.read_csv('creditcard.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"File 'creditcard.csv' not found. Downloading...\")\n",
        "    # Download the dataset from a publically accessible URL.\n",
        "    !wget https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv -O creditcard.csv\n",
        "    fraud_df = pd.read_csv('creditcard.csv')\n",
        "\n",
        "# Features and target\n",
        "X = fraud_df.drop('Class', axis=1)\n",
        "y = fraud_df['Class']\n",
        "\n",
        "# Handle class imbalance using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_resampled, y_resampled, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Train logistic regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions and evaluation\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Fraud Detection Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Tpgn-99gzGD",
        "outputId": "d9ea8b62-90d8-4950-a28a-3eff8df38e35"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fraud Detection Accuracy: 0.9795737122557726\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98     56750\n",
            "           1       0.99      0.97      0.98     56976\n",
            "\n",
            "    accuracy                           0.98    113726\n",
            "   macro avg       0.98      0.98      0.98    113726\n",
            "weighted avg       0.98      0.98      0.98    113726\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FcMhdQJGhPd8"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}